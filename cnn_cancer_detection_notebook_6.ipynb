{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb50c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/workspace'\n",
    "import keras\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_labels(data_dir='./', num_samples=None, balanced=False):\n",
    "    training_labels = pd.read_csv(os.path.join(data_dir, 'train_labels.csv'))\n",
    "    training_labels['label'] = training_labels['label'].astype('bool')\n",
    "    if num_samples is None:\n",
    "        return training_labels.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    if balanced:\n",
    "        pos = training_labels[training_labels['label']].sample(num_samples // 2)\n",
    "        neg = training_labels[~training_labels['label']].sample(num_samples // 2)\n",
    "        training_labels = pd.concat([pos, neg]).sample(frac=1).reset_index(drop=True)\n",
    "    else:\n",
    "        training_labels = training_labels.sample(num_samples).reset_index(drop=True)\n",
    "\n",
    "    return training_labels\n",
    "\n",
    "\n",
    "def get_training_images(training_labels, data_dir='./'):\n",
    "    images = np.array(\n",
    "        [keras.utils.img_to_array(keras.utils.load_img(os.path.join(data_dir, 'train', f'{id}.tif')))\n",
    "         for id in training_labels['id']])\n",
    "    return images\n",
    "\n",
    "\n",
    "def get_test_images(data_dir='./'):\n",
    "    test_image_files = [f for f in os.listdir(os.path.join(data_dir, \"test\")) if f.endswith(\".tif\")]\n",
    "    test_ids = [Path(f).stem for f in test_image_files]\n",
    "    test_images = np.array(\n",
    "        [keras.utils.img_to_array(keras.utils.load_img(os.path.join(data_dir, 'test', f)))\n",
    "         for f in test_image_files])\n",
    "    return test_images, test_ids\n",
    "\n",
    "\n",
    "def plot_training_history(history):\n",
    "    # Plot the training and validation loss and accuracy\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38fe3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name, X, y, epochs=100, batch_size=32, validation_split=0.2):\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        f'{model_name}.best_weights.keras', \n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor='val_AUC',\n",
    "        mode='max')\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        monitor='val_AUC',\n",
    "        mode='max')\n",
    "\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=validation_split, \n",
    "                        callbacks=[checkpointer, early_stopping])\n",
    "    \n",
    "    model.load_weights(f'{model_name}.best_weights.keras')\n",
    "    plot_training_history(history)\n",
    "    return model # , history\n",
    "\n",
    "\n",
    "def evaluate_model_and_print_results(model, X_test, y_test):\n",
    "    test_loss, test_accuracy, test_auc = model.evaluate(X_test, y_test)\n",
    "    print(f'Test Loss: {test_loss}')\n",
    "    print(f'Test Accuracy: {test_accuracy}')\n",
    "    print(f'Test AUC: {test_auc}')\n",
    "\n",
    "\n",
    "def generate_submission(model, test_images, test_ids, model_name):\n",
    "    test_predictions = model.predict(test_images)\n",
    "    submission = pd.DataFrame({\"id\": test_ids, \"label\": test_predictions.flatten()})\n",
    "    output_file = f'submission_{model_name}.csv'\n",
    "    submission.to_csv(output_file, index=False)\n",
    "    print(f\"Submission saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d423868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
